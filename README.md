Autonomous Driving Perception System (YOLOv8 + Python)

This project demonstrates a computer vision perception system for autonomous driving, built with Python and YOLOv8. The model is able to detect and classify vehicles in images, highlight them with bounding boxes, and save the annotated output for analysis. It simulates the perception component of self-driving systems that identify objects on the road.

The system uses Python 3.10, YOLOv8 from Ultralytics, OpenCV, and NumPy. When you run the program, it opens a file dialog to let you select an image. The YOLOv8 model then processes the image, detects vehicles, and displays the results on screen while also saving them as an output image file called output.jpg.

The project includes the main Python script, a requirements file for installing dependencies, and a demo recording of the program in action. The structure is simple: one script to run the detection, a requirements file to rebuild the environment, and outputs that show the results.

Future improvements could include enabling live webcam detection, filtering results to show only vehicles while ignoring other classes, and extending the system to work on continuous video frames.

This project was developed by Mahad Ahmed. More details and updates can be found on LinkedIn at https://www.linkedin.com/in/mahadahmed1218/
 and GitHub at https://github.com/mahadahmed1218
.
